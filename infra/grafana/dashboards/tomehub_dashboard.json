{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "grafana",
          "uid": "-- Grafana --"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "type": "dashboard"
      }
    ]
  },
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 0,
  "id": null,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "id": 16,
      "title": "System Health & Memory",
      "type": "row",
      "gridPos": {
        "x": 0,
        "y": 0,
        "w": 24,
        "h": 1
      }
    },
    {
      "id": 101,
      "title": "Backend Scrape Up",
      "type": "stat",
      "gridPos": {
        "x": 0,
        "y": 1,
        "w": 6,
        "h": 4
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "max(up{job=\"tomehub_backend\"}) or vector(0)"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "none"
        },
        "overrides": []
      },
      "options": {
        "colorMode": "value",
        "graphMode": "none",
        "justifyMode": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "orientation": "auto",
        "textMode": "auto"
      }
    },
    {
      "id": 102,
      "title": "AI Metric Last Seen (s)",
      "type": "stat",
      "gridPos": {
        "x": 6,
        "y": 1,
        "w": 6,
        "h": 4
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "time() - max(timestamp(tomehub_ai_service_duration_seconds_count))"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "s"
        },
        "overrides": []
      },
      "options": {
        "colorMode": "value",
        "graphMode": "none",
        "justifyMode": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "orientation": "auto",
        "textMode": "auto"
      }
    },
    {
      "id": 103,
      "title": "LLM Metric Last Seen (s)",
      "type": "stat",
      "gridPos": {
        "x": 12,
        "y": 1,
        "w": 6,
        "h": 4
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "time() - max(timestamp(tomehub_llm_calls_total))"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "s"
        },
        "overrides": []
      },
      "options": {
        "colorMode": "value",
        "graphMode": "none",
        "justifyMode": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "orientation": "auto",
        "textMode": "auto"
      }
    },
    {
      "id": 104,
      "title": "Ingestion Metric Last Seen (s)",
      "type": "stat",
      "gridPos": {
        "x": 18,
        "y": 1,
        "w": 6,
        "h": 4
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "time() - max(timestamp(tomehub_ingestion_duration_seconds_count))"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "s"
        },
        "overrides": []
      },
      "options": {
        "colorMode": "value",
        "graphMode": "none",
        "justifyMode": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "orientation": "auto",
        "textMode": "auto"
      }
    },
    {
      "id": 22,
      "title": "Circuit Breakers",
      "type": "gauge",
      "gridPos": {
        "x": 0,
        "y": 5,
        "w": 4,
        "h": 6
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "tomehub_circuit_breaker_state",
          "legendFormat": "{{service}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "none",
          "min": 0,
          "max": 2,
          "mappings": [
            {
              "type": "value",
              "options": {
                "0": {
                  "text": "CLOSED"
                },
                "1": {
                  "text": "HALF_OPEN"
                },
                "2": {
                  "text": "OPEN"
                }
              }
            }
          ],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "orange",
                "value": 1
              },
              {
                "color": "red",
                "value": 2
              }
            ]
          }
        },
        "overrides": []
      }
    },
    {
      "id": 4,
      "title": "API Latency (Avg)",
      "type": "timeseries",
      "gridPos": {
        "x": 4,
        "y": 5,
        "w": 10,
        "h": 6
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "rate(http_request_duration_seconds_sum[5m]) / rate(http_request_duration_seconds_count[5m])",
          "legendFormat": "Avg Latency"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "s"
        },
        "overrides": []
      },
      "options": {
        "legend": {
          "displayMode": "list",
          "placement": "bottom"
        },
        "tooltip": {
          "mode": "multi",
          "sort": "none"
        }
      },
      "pluginVersion": "10.0.0"
    },
    {
      "id": 24,
      "title": "AI Service Latency (Internal)",
      "type": "timeseries",
      "gridPos": {
        "x": 14,
        "y": 5,
        "w": 10,
        "h": 6
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "sum by (service, operation) (rate(tomehub_ai_service_duration_seconds_sum[5m])) / sum by (service, operation) (rate(tomehub_ai_service_duration_seconds_count[5m]))",
          "legendFormat": "{{service}} ({{operation}})"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "s"
        },
        "overrides": []
      },
      "options": {
        "legend": {
          "displayMode": "list",
          "placement": "bottom"
        },
        "tooltip": {
          "mode": "multi",
          "sort": "none"
        }
      },
      "pluginVersion": "10.0.0"
    },
    {
      "id": 18,
      "title": "Database Resilience",
      "type": "row",
      "gridPos": {
        "x": 0,
        "y": 11,
        "w": 24,
        "h": 1
      }
    },
    {
      "id": 26,
      "title": "DB Pool Utilization (Read)",
      "type": "timeseries",
      "gridPos": {
        "x": 0,
        "y": 12,
        "w": 12,
        "h": 8
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "tomehub_db_pool_utilization{pool_type=\"read\", metric_type=\"active\"}",
          "legendFormat": "Active"
        },
        {
          "expr": "tomehub_db_pool_utilization{pool_type=\"read\", metric_type=\"max\"}",
          "legendFormat": "Max Cap"
        }
      ],
      "fieldConfig": {
        "defaults": {},
        "overrides": []
      },
      "options": {
        "legend": {
          "displayMode": "list",
          "placement": "bottom"
        },
        "tooltip": {
          "mode": "multi",
          "sort": "none"
        }
      },
      "pluginVersion": "10.0.0"
    },
    {
      "id": 28,
      "title": "DB Pool Utilization (Write)",
      "type": "timeseries",
      "gridPos": {
        "x": 12,
        "y": 12,
        "w": 12,
        "h": 8
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "tomehub_db_pool_utilization{pool_type=\"write\", metric_type=\"active\"}",
          "legendFormat": "Active"
        },
        {
          "expr": "tomehub_db_pool_utilization{pool_type=\"write\", metric_type=\"max\"}",
          "legendFormat": "Max Cap"
        }
      ],
      "fieldConfig": {
        "defaults": {},
        "overrides": []
      },
      "options": {
        "legend": {
          "displayMode": "list",
          "placement": "bottom"
        },
        "tooltip": {
          "mode": "multi",
          "sort": "none"
        }
      },
      "pluginVersion": "10.0.0"
    },
    {
      "id": 20,
      "title": "Ingestion Pipeline",
      "type": "row",
      "gridPos": {
        "x": 0,
        "y": 20,
        "w": 24,
        "h": 1
      }
    },
    {
      "id": 30,
      "title": "Ingestion Success vs Fail",
      "type": "timeseries",
      "gridPos": {
        "x": 0,
        "y": 21,
        "w": 8,
        "h": 8
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "sum(increase(tomehub_ingestion_duration_seconds_count{status=\"success\"}[1h])) or vector(0)",
          "legendFormat": "Success"
        },
        {
          "expr": "sum(increase(tomehub_ingestion_duration_seconds_count{status=\"fail\"}[1h])) or vector(0)",
          "legendFormat": "Fail"
        }
      ],
      "fieldConfig": {
        "defaults": {},
        "overrides": []
      },
      "options": {
        "legend": {
          "displayMode": "list",
          "placement": "bottom"
        },
        "tooltip": {
          "mode": "multi",
          "sort": "none"
        }
      },
      "pluginVersion": "10.0.0"
    },
    {
      "id": 32,
      "title": "Ingestion Latency Distribution",
      "type": "heatmap",
      "gridPos": {
        "x": 8,
        "y": 21,
        "w": 8,
        "h": 8
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "sum(rate(tomehub_ingestion_duration_seconds_bucket[5m])) by (le)",
          "format": "heatmap"
        }
      ],
      "options": {
        "calculate": false
      }
    },
    {
      "id": 105,
      "title": "Ingestion Events (1h)",
      "type": "stat",
      "gridPos": {
        "x": 16,
        "y": 21,
        "w": 8,
        "h": 8
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "sum(increase(tomehub_ingestion_duration_seconds_count[1h])) or vector(0)"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "none"
        },
        "overrides": []
      },
      "options": {
        "colorMode": "value",
        "graphMode": "none",
        "justifyMode": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "orientation": "auto",
        "textMode": "auto"
      }
    },
    {
      "id": 34,
      "title": "Epistemic Quality (Judge AI)",
      "type": "row",
      "gridPos": {
        "x": 0,
        "y": 29,
        "w": 24,
        "h": 1
      }
    },
    {
      "id": 6,
      "title": "Judge AI Score Distribution",
      "type": "heatmap",
      "gridPos": {
        "x": 0,
        "y": 30,
        "w": 8,
        "h": 8
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "sum(rate(tomehub_judge_score_bucket[5m])) by (le)",
          "format": "heatmap"
        }
      ],
      "options": {
        "calculate": false
      }
    },
    {
      "id": 8,
      "title": "Judge Verdicts (Pass vs Regenerate)",
      "type": "timeseries",
      "gridPos": {
        "x": 8,
        "y": 30,
        "w": 8,
        "h": 8
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "sum(increase(tomehub_judge_score_count{verdict=\"PASS\"}[1h])) or vector(0)",
          "legendFormat": "PASS"
        },
        {
          "expr": "sum(increase(tomehub_judge_score_count{verdict=\"REGENERATE\"}[1h])) or vector(0)",
          "legendFormat": "REGENERATE"
        },
        {
          "expr": "sum(increase(tomehub_judge_score_count{verdict=\"DECLINE\"}[1h])) or vector(0)",
          "legendFormat": "DECLINE"
        }
      ],
      "fieldConfig": {
        "defaults": {},
        "overrides": []
      },
      "options": {
        "legend": {
          "displayMode": "list",
          "placement": "bottom"
        },
        "tooltip": {
          "mode": "multi",
          "sort": "none"
        }
      },
      "pluginVersion": "10.0.0"
    },
    {
      "id": 106,
      "title": "Judge Events (1h)",
      "type": "stat",
      "gridPos": {
        "x": 16,
        "y": 30,
        "w": 8,
        "h": 8
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "sum(increase(tomehub_judge_score_count[1h])) or vector(0)"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "none"
        },
        "overrides": []
      },
      "options": {
        "colorMode": "value",
        "graphMode": "none",
        "justifyMode": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "orientation": "auto",
        "textMode": "auto"
      }
    }
  ],
  "refresh": "5s",
  "schemaVersion": 38,
  "style": "dark",
  "tags": [
    "tomehub"
  ],
  "templating": {
    "list": []
  },
  "time": {
    "from": "now-1h",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "",
  "title": "TomeHub Unified Observability",
  "uid": "tomehub-main",
  "version": 3,
  "weekStart": ""
}
