{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": {
          "type": "grafana",
          "uid": "-- Grafana --"
        },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "type": "dashboard"
      }
    ]
  },
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 0,
  "id": null,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "id": 201,
      "title": "LLM Traffic & Provider Mix",
      "type": "row",
      "gridPos": {
        "x": 0,
        "y": 0,
        "w": 24,
        "h": 1
      }
    },
    {
      "id": 202,
      "title": "LLM Calls (1h)",
      "type": "stat",
      "gridPos": {
        "x": 0,
        "y": 1,
        "w": 4,
        "h": 6
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "sum(increase(tomehub_llm_calls_total[1h])) or vector(0)"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "none"
        },
        "overrides": []
      },
      "options": {
        "colorMode": "value",
        "graphMode": "none",
        "justifyMode": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "orientation": "auto",
        "textMode": "auto"
      }
    },
    {
      "id": 203,
      "title": "Provider Calls by Status (5m rate)",
      "type": "timeseries",
      "gridPos": {
        "x": 4,
        "y": 1,
        "w": 10,
        "h": 6
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "sum by (provider, status) (rate(tomehub_llm_provider_calls_total{provider=~\"$provider\"}[5m]))",
          "legendFormat": "{{provider}} {{status}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "custom": {
            "stacking": {
              "mode": "normal",
              "group": "A"
            }
          }
        },
        "overrides": []
      },
      "options": {
        "legend": {
          "displayMode": "list",
          "placement": "bottom"
        },
        "tooltip": {
          "mode": "multi",
          "sort": "none"
        }
      },
      "pluginVersion": "10.0.0"
    },
    {
      "id": 204,
      "title": "Provider Share (1h)",
      "type": "piechart",
      "gridPos": {
        "x": 14,
        "y": 1,
        "w": 5,
        "h": 6
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "sum by (provider) (increase(tomehub_llm_provider_calls_total{provider=~\"$provider\",status=\"success\"}[1h]))"
        }
      ],
      "options": {
        "legend": {
          "displayMode": "list",
          "placement": "right"
        },
        "pieType": "pie",
        "displayLabels": [
          "name",
          "percent"
        ]
      }
    },
    {
      "id": 205,
      "title": "Fallback Events by Reason (1h)",
      "type": "barchart",
      "gridPos": {
        "x": 19,
        "y": 1,
        "w": 5,
        "h": 6
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "sum by (from_provider, to_provider, reason) (increase(tomehub_llm_fallback_total[1h])) or vector(0)"
        }
      ],
      "options": {
        "orientation": "auto",
        "showValue": "auto"
      }
    },
    {
      "id": 206,
      "title": "Token Analytics",
      "type": "row",
      "gridPos": {
        "x": 0,
        "y": 7,
        "w": 24,
        "h": 1
      }
    },
    {
      "id": 207,
      "title": "Tokens / min by Direction",
      "type": "timeseries",
      "gridPos": {
        "x": 0,
        "y": 8,
        "w": 8,
        "h": 7
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "sum by (direction) (rate(tomehub_llm_tokens_total{task=~\"$task\",model_tier=~\"$model_tier\"}[5m]))",
          "legendFormat": "{{direction}}"
        }
      ],
      "fieldConfig": {
        "defaults": {},
        "overrides": []
      },
      "options": {
        "legend": {
          "displayMode": "list",
          "placement": "bottom"
        },
        "tooltip": {
          "mode": "multi",
          "sort": "none"
        }
      },
      "pluginVersion": "10.0.0"
    },
    {
      "id": 208,
      "title": "Token Volume (1h by task/direction)",
      "type": "barchart",
      "gridPos": {
        "x": 8,
        "y": 8,
        "w": 8,
        "h": 7
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "sum by (task, direction) (increase(tomehub_llm_tokens_total{task=~\"$task\",model_tier=~\"$model_tier\"}[1h]))"
        }
      ],
      "options": {
        "orientation": "auto",
        "showValue": "auto"
      }
    },
    {
      "id": 209,
      "title": "Avg Total Tokens / Successful Call (1h)",
      "type": "stat",
      "gridPos": {
        "x": 16,
        "y": 8,
        "w": 8,
        "h": 7
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "sum(increase(tomehub_llm_tokens_total{direction=\"total\",task=~\"$task\",model_tier=~\"$model_tier\"}[1h])) / clamp_min(sum(increase(tomehub_llm_calls_total{status=\"success\",task=~\"$task\",model_tier=~\"$model_tier\"}[1h])), 1)"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "none"
        },
        "overrides": []
      },
      "options": {
        "colorMode": "value",
        "graphMode": "none",
        "justifyMode": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "orientation": "auto",
        "textMode": "auto"
      }
    },
    {
      "id": 210,
      "title": "AI / LLM Latency",
      "type": "row",
      "gridPos": {
        "x": 0,
        "y": 15,
        "w": 24,
        "h": 1
      }
    },
    {
      "id": 211,
      "title": "AI Service Avg Latency by Service+Op",
      "type": "timeseries",
      "gridPos": {
        "x": 0,
        "y": 16,
        "w": 8,
        "h": 7
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "sum by (service, operation) (rate(tomehub_ai_service_duration_seconds_sum{service=~\"$service\"}[5m])) / sum by (service, operation) (rate(tomehub_ai_service_duration_seconds_count{service=~\"$service\"}[5m]))",
          "legendFormat": "{{service}} {{operation}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "s"
        },
        "overrides": []
      },
      "options": {
        "legend": {
          "displayMode": "list",
          "placement": "bottom"
        },
        "tooltip": {
          "mode": "multi",
          "sort": "none"
        }
      },
      "pluginVersion": "10.0.0"
    },
    {
      "id": 212,
      "title": "AI Service p95 Latency",
      "type": "timeseries",
      "gridPos": {
        "x": 8,
        "y": 16,
        "w": 8,
        "h": 7
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "histogram_quantile(0.95, sum by (le, service, operation) (rate(tomehub_ai_service_duration_seconds_bucket{service=~\"$service\"}[5m])))",
          "legendFormat": "{{service}} {{operation}} p95"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "s"
        },
        "overrides": []
      },
      "options": {
        "legend": {
          "displayMode": "list",
          "placement": "bottom"
        },
        "tooltip": {
          "mode": "multi",
          "sort": "none"
        }
      },
      "pluginVersion": "10.0.0"
    },
    {
      "id": 213,
      "title": "AI Service Calls (5m rate)",
      "type": "timeseries",
      "gridPos": {
        "x": 16,
        "y": 16,
        "w": 8,
        "h": 7
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "sum by (service, operation) (rate(tomehub_ai_service_duration_seconds_count{service=~\"$service\"}[5m]))",
          "legendFormat": "{{service}} {{operation}}"
        }
      ],
      "fieldConfig": {
        "defaults": {},
        "overrides": []
      },
      "options": {
        "legend": {
          "displayMode": "list",
          "placement": "bottom"
        },
        "tooltip": {
          "mode": "multi",
          "sort": "none"
        }
      },
      "pluginVersion": "10.0.0"
    },
    {
      "id": 214,
      "title": "RAG Quality Signals",
      "type": "row",
      "gridPos": {
        "x": 0,
        "y": 23,
        "w": 24,
        "h": 1
      }
    },
    {
      "id": 215,
      "title": "Search Fusion Mode Usage (1h)",
      "type": "barchart",
      "gridPos": {
        "x": 0,
        "y": 24,
        "w": 6,
        "h": 8
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "sum by (fusion_mode) (increase(tomehub_search_fusion_mode_total[1h])) or vector(0)"
        }
      ],
      "options": {
        "orientation": "auto",
        "showValue": "auto"
      }
    },
    {
      "id": 216,
      "title": "Graph Bridges Distribution",
      "type": "heatmap",
      "gridPos": {
        "x": 6,
        "y": 24,
        "w": 6,
        "h": 8
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "sum(rate(tomehub_graph_bridges_found_bucket[5m])) by (le)",
          "format": "heatmap"
        }
      ],
      "options": {
        "calculate": false
      }
    },
    {
      "id": 217,
      "title": "Search Result Count Distribution",
      "type": "heatmap",
      "gridPos": {
        "x": 12,
        "y": 24,
        "w": 6,
        "h": 8
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "sum(rate(tomehub_search_result_count_bucket[5m])) by (le)",
          "format": "heatmap"
        }
      ],
      "options": {
        "calculate": false
      }
    },
    {
      "id": 218,
      "title": "Source Diversity Distribution",
      "type": "heatmap",
      "gridPos": {
        "x": 18,
        "y": 24,
        "w": 6,
        "h": 8
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "sum(rate(tomehub_search_diversity_source_count_bucket[5m])) by (le)",
          "format": "heatmap"
        }
      ],
      "options": {
        "calculate": false
      }
    },
    {
      "id": 219,
      "title": "L3 Phase Latency p95",
      "type": "timeseries",
      "gridPos": {
        "x": 0,
        "y": 32,
        "w": 24,
        "h": 6
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "histogram_quantile(0.95, sum by (le, phase) (rate(tomehub_l3_phase_latency_seconds_bucket[5m])))",
          "legendFormat": "{{phase}} p95"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "s"
        },
        "overrides": []
      },
      "options": {
        "legend": {
          "displayMode": "list",
          "placement": "bottom"
        },
        "tooltip": {
          "mode": "multi",
          "sort": "none"
        }
      },
      "pluginVersion": "10.0.0"
    },
    {
      "id": 220,
      "title": "Reliability (HTTP + Infra quick view)",
      "type": "row",
      "gridPos": {
        "x": 0,
        "y": 38,
        "w": 24,
        "h": 1
      }
    },
    {
      "id": 221,
      "title": "HTTP 5xx Rate",
      "type": "timeseries",
      "gridPos": {
        "x": 0,
        "y": 39,
        "w": 8,
        "h": 6
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "sum(rate(http_requests_total{status=~\"5..\"}[5m])) or vector(0)",
          "legendFormat": "5xx rate"
        }
      ],
      "fieldConfig": {
        "defaults": {},
        "overrides": []
      },
      "options": {
        "legend": {
          "displayMode": "list",
          "placement": "bottom"
        },
        "tooltip": {
          "mode": "multi",
          "sort": "none"
        }
      },
      "pluginVersion": "10.0.0"
    },
    {
      "id": 222,
      "title": "HTTP Error Rate %",
      "type": "stat",
      "gridPos": {
        "x": 8,
        "y": 39,
        "w": 8,
        "h": 6
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "sum(rate(http_requests_total{status=~\"5..\"}[5m])) / clamp_min(sum(rate(http_requests_total[5m])), 1)"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "percentunit"
        },
        "overrides": []
      },
      "options": {
        "colorMode": "value",
        "graphMode": "none",
        "justifyMode": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "orientation": "auto",
        "textMode": "auto"
      }
    },
    {
      "id": 223,
      "title": "Backend Uptime (s)",
      "type": "stat",
      "gridPos": {
        "x": 16,
        "y": 39,
        "w": 4,
        "h": 6
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "time() - process_start_time_seconds"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "s"
        },
        "overrides": []
      },
      "options": {
        "colorMode": "value",
        "graphMode": "none",
        "justifyMode": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "orientation": "auto",
        "textMode": "auto"
      }
    },
    {
      "id": 224,
      "title": "Redis Availability",
      "type": "stat",
      "gridPos": {
        "x": 20,
        "y": 39,
        "w": 4,
        "h": 6
      },
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "tomehub_redis_available{layer=\"l2_cache\"}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "none",
          "mappings": [
            {
              "type": "value",
              "options": {
                "0": {
                  "text": "DOWN"
                },
                "1": {
                  "text": "UP"
                }
              }
            }
          ]
        },
        "overrides": []
      },
      "options": {
        "colorMode": "value",
        "graphMode": "none",
        "justifyMode": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "orientation": "auto",
        "textMode": "auto"
      }
    }
  ],
  "refresh": "10s",
  "schemaVersion": 38,
  "style": "dark",
  "tags": [
    "tomehub"
  ],
  "templating": {
    "list": [
      {
        "name": "provider",
        "type": "query",
        "datasource": "Prometheus",
        "refresh": 2,
        "includeAll": true,
        "multi": true,
        "allValue": ".*",
        "query": "label_values(tomehub_llm_provider_calls_total, provider)",
        "definition": "label_values(tomehub_llm_provider_calls_total, provider)",
        "current": {
          "selected": true,
          "text": [
            "All"
          ],
          "value": [
            "$__all"
          ]
        }
      },
      {
        "name": "task",
        "type": "query",
        "datasource": "Prometheus",
        "refresh": 2,
        "includeAll": true,
        "multi": true,
        "allValue": ".*",
        "query": "label_values(tomehub_llm_calls_total, task)",
        "definition": "label_values(tomehub_llm_calls_total, task)",
        "current": {
          "selected": true,
          "text": [
            "All"
          ],
          "value": [
            "$__all"
          ]
        }
      },
      {
        "name": "model_tier",
        "type": "query",
        "datasource": "Prometheus",
        "refresh": 2,
        "includeAll": true,
        "multi": true,
        "allValue": ".*",
        "query": "label_values(tomehub_llm_calls_total, model_tier)",
        "definition": "label_values(tomehub_llm_calls_total, model_tier)",
        "current": {
          "selected": true,
          "text": [
            "All"
          ],
          "value": [
            "$__all"
          ]
        }
      },
      {
        "name": "service",
        "type": "query",
        "datasource": "Prometheus",
        "refresh": 2,
        "includeAll": true,
        "multi": true,
        "allValue": ".*",
        "query": "label_values(tomehub_ai_service_duration_seconds_count, service)",
        "definition": "label_values(tomehub_ai_service_duration_seconds_count, service)",
        "current": {
          "selected": true,
          "text": [
            "All"
          ],
          "value": [
            "$__all"
          ]
        }
      }
    ]
  },
  "time": {
    "from": "now-6h",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "",
  "title": "TomeHub LLM & RAG Deep Dive",
  "uid": "tomehub-llm-rag",
  "version": 1,
  "weekStart": ""
}
