#!/usr/bin/env python3
"""
TomeHub Kitaplar (Books) Depolama Analizi
Books table schema, data organization, relationships
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'apps', 'backend'))

from infrastructure.db_manager import DatabaseManager

def analyze_books_schema():
    """Kitaplar tablosu ÅŸemasÄ±nÄ± analiz et"""
    print("\n" + "="*80)
    print("ğŸ“š TOMEHUB_BOOKS TABLO ÅEMASI")
    print("="*80)
    
    with DatabaseManager.get_connection() as conn:
        with conn.cursor() as cursor:
            # TOMEHUB_BOOKS yapÄ±sÄ±
            query = """
            SELECT COLUMN_NAME, DATA_TYPE, NULLABLE
            FROM USER_TAB_COLUMNS 
            WHERE TABLE_NAME = 'TOMEHUB_BOOKS'
            ORDER BY COLUMN_ID
            """
            cursor.execute(query)
            
            print("\nâœ“ TOMEHUB_BOOKS KolonlarÄ±:")
            print("-" * 80)
            for col_name, data_type, nullable in cursor.fetchall():
                null_status = "NULL alabiliyor" if nullable == 'Y' else "NOT NULL"
                print(f"  {col_name:25s} {data_type:20s} [{null_status}]")

def analyze_books_data():
    """Kitaplar verilerini analiz et"""
    print("\n" + "="*80)
    print("ğŸ“Š TOMEHUB_BOOKS VERÄ° ANALÄ°ZÄ°")
    print("="*80)
    
    with DatabaseManager.get_connection() as conn:
        with conn.cursor() as cursor:
            # Toplam kitap sayÄ±sÄ±
            query = "SELECT COUNT(*) FROM TOMEHUB_BOOKS"
            cursor.execute(query)
            total_books = cursor.fetchone()[0]
            
            print(f"\nâœ“ Toplam kitap sayÄ±sÄ±: {total_books}")
            
            # KitaplarÄ±n detaylÄ± bilgileri
            query = """
            SELECT 
                COUNT(DISTINCT FIREBASE_UID) as unique_users,
                COUNT(DISTINCT TITLE) as unique_titles,
                COUNT(AUTHOR) as books_with_author,
                COUNT(TOTAL_CHUNKS) as books_with_chunks,
                SUM(TOTAL_CHUNKS) as total_chunks_sum
            FROM TOMEHUB_BOOKS
            """
            cursor.execute(query)
            users, titles, with_author, with_chunks, chunks_sum = cursor.fetchone()
            
            print(f"\nâœ“ Kitap Metadata TamlÄ±ÄŸÄ±:")
            print(f"  â€¢ FarklÄ± kullanÄ±cÄ±lar: {users}")
            print(f"  â€¢ FarklÄ± baÅŸlÄ±klar: {titles}")
            print(f"  â€¢ Yazar bilgili kitaplar: {with_author}/{total_books} ({100*with_author/total_books:.1f}%)")
            print(f"  â€¢ TOTAL_CHUNKS bilgisi olan: {with_chunks}/{total_books} ({100*with_chunks/total_books:.1f}%)")
            print(f"  â€¢ Toplam chunks: {chunks_sum or 0:,}")
            
            # En popÃ¼ler kitaplar (en fazla chunk)
            print(f"\nâœ“ En PopÃ¼ler 10 Kitap (Chunk SayÄ±sÄ±na GÃ¶re):")
            print("-" * 80)
            query = """
            SELECT 
                ID,
                TITLE,
                TOTAL_CHUNKS,
                AUTHOR,
                CREATED_AT,
                LAST_UPDATED
            FROM TOMEHUB_BOOKS
            WHERE TOTAL_CHUNKS IS NOT NULL
            ORDER BY TOTAL_CHUNKS DESC
            FETCH FIRST 10 ROWS ONLY
            """
            cursor.execute(query)
            
            for book_id, title, chunks, author, created, updated in cursor.fetchall():
                author_str = f" by {author}" if author else ""
                print(f"  {book_id:3s}. {title:35s} {author_str:25s} | {chunks:4.0f} chunks")

def analyze_books_relationships():
    """Kitaplar ile diÄŸer tablolar arasÄ±ndaki iliÅŸkileri analiz et"""
    print("\n" + "="*80)
    print("ğŸ”— KÄ°TAPLAR Ä°LÄ°ÅKÄ°LERÄ°")
    print("="*80)
    
    with DatabaseManager.get_connection() as conn:
        with conn.cursor() as cursor:
            # TOMEHUB_CONTENT'teki BOOK_ID ve TITLE kullanÄ±mÄ±
            query = """
            SELECT 
                COUNT(*) as total_content,
                SUM(CASE WHEN TITLE IS NOT NULL THEN 1 ELSE 0 END) as content_with_title,
                COUNT(DISTINCT TITLE) as unique_titles_in_content
            FROM TOMEHUB_CONTENT
            """
            cursor.execute(query)
            total_content, with_title, unique_titles = cursor.fetchone()
            
            print(f"\nâœ“ TOMEHUB_CONTENT Ä°Ã§erik Ä°liÅŸkileri:")
            print(f"  â€¢ Toplam iÃ§erik: {total_content:,}")
            print(f"  â€¢ TITLE'Ä± olan: {with_title:,} ({100*with_title/total_content:.1f}%)")
            print(f"  â€¢ FarklÄ± baÅŸlÄ±klar referansÄ±: {unique_titles}")
            
            # Kitaplar ile iÃ§erik eÅŸleÅŸmesi
            query = """
            SELECT 
                b.TITLE as book_title,
                COUNT(c.ID) as matching_content,
                b.TOTAL_CHUNKS as declared_chunks
            FROM TOMEHUB_BOOKS b
            LEFT JOIN TOMEHUB_CONTENT c ON TRIM(b.TITLE) = TRIM(c.TITLE)
            GROUP BY b.ID, b.TITLE, b.TOTAL_CHUNKS
            ORDER BY matching_content DESC
            FETCH FIRST 15 ROWS ONLY
            """
            cursor.execute(query)
            
            print(f"\nâœ“ Kitaplar ve EÅŸleÅŸen Ä°Ã§erik (TITLE bazlÄ±):")
            print("-" * 80)
            for book_title, matching, declared in cursor.fetchall():
                match_status = "âœ“" if matching == declared else "âš ï¸"
                print(f"  {match_status} {book_title:40s} â†’ {matching:4d} matches / {declared or 0:4.0f} declared")

def analyze_content_by_book():
    """Kitaplara gÃ¶re iÃ§erik daÄŸÄ±lÄ±mÄ±nÄ± analiz et"""
    print("\n" + "="*80)
    print("ğŸ“– KÄ°TAP BAÅINA Ä°Ã‡ERÄ°K DAÄILIMI")
    print("="*80)
    
    with DatabaseManager.get_connection() as conn:
        with conn.cursor() as cursor:
            # Ä°Ã§erik kaynaklarÄ±nÄ±n daÄŸÄ±lÄ±mÄ±
            query = """
            SELECT 
                COUNT(*) as total_content,
                COUNT(DISTINCT TITLE) as distinct_books,
                COUNT(DISTINCT SOURCE_TYPE) as source_types
            FROM TOMEHUB_CONTENT
            """
            cursor.execute(query)
            total_content, distinct_books, source_types = cursor.fetchone()
            
            print(f"\nâœ“ Ä°Ã§erik Ã–zeti:")
            print("-" * 80)
            print(f"  â€¢ Toplam iÃ§erik chunks: {total_content:,}")
            print(f"  â€¢ FarklÄ± kitap baÅŸlÄ±klarÄ±: {distinct_books}")
            print(f"  â€¢ FarklÄ± kaynak tipi: {source_types}")
            
            # Kaynak tiplerine gÃ¶re daÄŸÄ±lÄ±m
            print(f"\nâœ“ Ä°Ã§erik - Kaynak Tipi DaÄŸÄ±lÄ±mÄ±:")
            print("-" * 80)
            query = """
            SELECT 
                SOURCE_TYPE,
                COUNT(*) as count,
                COUNT(DISTINCT TITLE) as book_count
            FROM TOMEHUB_CONTENT
            GROUP BY SOURCE_TYPE
            ORDER BY count DESC
            """
            cursor.execute(query)
            
            for source_type, count, book_count in cursor.fetchall():
                print(f"  {source_type:20s}: {count:5,} chunks ({book_count:3} kitap)")

def analyze_book_metadata_quality():
    """Kitap metadata kalitesini analiz et"""
    print("\n" + "="*80)
    print("âœ… KÄ°TAP METADATA KALÄ°TESÄ°")
    print("="*80)
    
    with DatabaseManager.get_connection() as conn:
        with conn.cursor() as cursor:
            # Her kitap iÃ§in metadata deÄŸerlendirmesi
            query = """
            SELECT 
                TITLE,
                CASE WHEN AUTHOR IS NOT NULL THEN 1 ELSE 0 END as has_author,
                CASE WHEN TOTAL_CHUNKS IS NOT NULL THEN 1 ELSE 0 END as has_chunks,
                CASE WHEN LAST_UPDATED IS NOT NULL THEN 1 ELSE 0 END as has_updated,
                TRUNC(CREATED_AT) as created_date,
                TOTAL_CHUNKS,
                (CASE WHEN AUTHOR IS NOT NULL THEN 1 ELSE 0 END +
                 CASE WHEN TOTAL_CHUNKS IS NOT NULL THEN 1 ELSE 0 END +
                 CASE WHEN LAST_UPDATED IS NOT NULL THEN 1 ELSE 0 END) as metadata_score
            FROM TOMEHUB_BOOKS
            ORDER BY metadata_score DESC, TITLE
            """
            cursor.execute(query)
            
            rows = cursor.fetchall()
            
            print(f"\nâœ“ Metadata Skor DaÄŸÄ±lÄ±mÄ±:")
            score_distribution = {}
            for row in rows:
                score = row[-1]
                score_distribution[score] = score_distribution.get(score, 0) + 1
            
            for score in sorted(score_distribution.keys(), reverse=True):
                count = score_distribution[score]
                total = len(rows)
                metadata_items = ['AUTHOR', 'TOTAL_CHUNKS', 'LAST_UPDATED']
                filled = ', '.join(metadata_items[:score]) if score > 0 else 'Eksik'
                print(f"  Skor {score}/3 ({filled:40s}): {count:3d} kitap ({100*count/total:5.1f}%)")
            
            # En iyi ve en kÃ¶tÃ¼ metadata olan kitaplar
            print(f"\nâœ“ En Tam Metadata'ya Sahip Kitaplar:")
            print("-" * 80)
            count = 0
            for row in rows:
                if count >= 5:
                    break
                title, has_author, has_chunks, has_updated, created_date, chunks, score = row
                auth_icon = "âœ“" if has_author else "âœ—"
                chunk_icon = "âœ“" if has_chunks else "âœ—"
                updated_icon = "âœ“" if has_updated else "âœ—"
                print(f"  [{score}/3] {title:45s} | {auth_icon} A {chunk_icon} C {updated_icon} U | Chunks: {chunks or 'N/A'}")

def analyze_book_users():
    """KitaplarÄ± kim eklemiÅŸti analiz et"""
    print("\n" + "="*80)
    print("ğŸ‘¥ KÄ°TAP EKLEYENLERÄ°N DAÄILIMI")
    print("="*80)
    
    with DatabaseManager.get_connection() as conn:
        with conn.cursor() as cursor:
            # KullanÄ±cÄ± baÅŸÄ±na kitap sayÄ±sÄ±
            query = """
            SELECT 
                FIREBASE_UID,
                COUNT(*) as books,
                COUNT(DISTINCT TITLE) as unique_titles,
                COUNT(AUTHOR) as with_author,
                MIN(CREATED_AT) as first_book_date,
                MAX(CREATED_AT) as last_book_date,
                ROUND(AVG(TOTAL_CHUNKS), 1) as avg_chunks
            FROM TOMEHUB_BOOKS
            GROUP BY FIREBASE_UID
            ORDER BY books DESC
            """
            cursor.execute(query)
            
            print(f"\nâœ“ KullanÄ±cÄ± BaÅŸÄ±na Kitap SayÄ±sÄ±:")
            print("-" * 80)
            for firebase_uid, books, unique_titles, with_author, first_date, last_date, avg_chunks in cursor.fetchall():
                print(f"  UID: {firebase_uid}")
                print(f"    â€¢ Kitap sayÄ±sÄ±: {books}")
                print(f"    â€¢ FarklÄ± baÅŸlÄ±klar: {unique_titles}")
                print(f"    â€¢ Yazar bilgili: {with_author}/{books}")
                print(f"    â€¢ Ortalama chunks: {avg_chunks or 'N/A'}")
                print(f"    â€¢ Ä°lk ekleme: {first_date}")
                print(f"    â€¢ Son ekleme: {last_date}")
                print()

def analyze_related_tables():
    """Kitaplarla ilgili diÄŸer tablolarÄ± kontrol et"""
    print("\n" + "="*80)
    print("ğŸ” KÄ°TAPLARLA Ä°LGÄ°LÄ° DÄ°ÄER TABLOLAR")
    print("="*80)
    
    with DatabaseManager.get_connection() as conn:
        with conn.cursor() as cursor:
            # TÃ¼m TOMEHUB tablolarÄ±
            query = """
            SELECT TABLE_NAME 
            FROM USER_TABLES 
            WHERE TABLE_NAME LIKE 'TOMEHUB%'
            ORDER BY TABLE_NAME
            """
            cursor.execute(query)
            tables = [row[0] for row in cursor.fetchall()]
            
            print(f"\nâœ“ TOMEHUB TablolarÄ± ({len(tables)} adet):")
            print("-" * 80)
            
            # Kitaplarla iliÅŸkili tablolar
            book_related_tables = [
                ('TOMEHUB_BOOKS', 'Ana kitap kaydÄ±'),
                ('TOMEHUB_CONTENT', 'TITLE ile baÄŸlantÄ±lÄ± iÃ§erik'),
            ]
            
            for table, description in book_related_tables:
                cursor.execute(f"SELECT COUNT(*) FROM {table}")
                row_count = cursor.fetchone()[0]
                print(f"  {table:40s} â†’ {row_count:6,} satÄ±r ({description})")

def generate_recommendations():
    """Ã–neriler ve iyileÅŸtirmeler"""
    print("\n" + "="*80)
    print("ğŸ’¡ Ã–NERÄ°LER VE Ä°YÄ°LEÅTÄ°RME ALANLAR")
    print("="*80)
    
    print("""
âœ“ Mevcut Durum:
  â€¢ Kitaplar, TOMEHUB_BOOKS tablosu'nda merkezi olarak depolanÄ±yor (88 adet)
  â€¢ Her kitabÄ±n TITLE'Ä±, TOMEHUB_CONTENT'teki TITLE sÃ¼tunuyla eÅŸleÅŸtirilir
  â€¢ TOTAL_CHUNKS sÃ¼tunu, kitap baÅŸÄ±na chunk sayÄ±sÄ±nÄ± takip ediyor
  â€¢ Multi-tenant yapÄ± (her kitap bir FIREBASE_UID'ye ait)
  â€¢ CREATED_AT ve LAST_UPDATED zeitempel vardÄ±r

âœ“ Depolama YapÄ±sÄ±:
  1. TOMEHUB_BOOKS (ID, TITLE, AUTHOR, FIREBASE_UID, CREATED_AT, TOTAL_CHUNKS, LAST_UPDATED)
  2. TOMEHUB_CONTENT (4,222 satÄ±r) â†’ TITLE ile kitaplara baÄŸlantÄ±
  3. Mapping: CONTENT.TITLE = BOOKS.TITLE

âš ï¸ Bulgular:
  â€¢ 87/88 kitabÄ±n yazar bilgisi eksik (98.9% boÅŸ, 0 metadata)
  â€¢ TOTAL_CHUNKS ve LAST_UPDATED deÄŸiÅŸkeni tabanlÄ± doldurma durumundan emin deÄŸil
  â€¢ 4,222 iÃ§erik chunks'Ä± var, distributed across 88 books
  â€¢ BazÄ± iÃ§erikler kitaptan tÃ¼retilmemiÅŸ (PERSONAL_NOTE, WEBSITE vb.)
  
ğŸš€ Ä°yileÅŸtirme Ã–nerileri:
  1. Yazar metadata'sÄ±nÄ± tamamla (aÃ§Ä±k API veya manuel entry)
  2. TOTAL_CHUNKS'Ä± otomatikleÅŸtir (trigger veya view)
  3. LAST_UPDATED'Ä± content gÃ¼ncellemelerine dayandÄ±r
  4. Ä°Ã§erik-kitap eÅŸleÅŸtirme algoritmayÄ± gÃ¼Ã§lendir (fuzzy matching)
  5. Kitap tarafÄ±ndan iÃ§erik tipi daÄŸÄ±lÄ±mÄ±nÄ± raporla
  6. Kitap birleÅŸtirme (merge) yetenekleri ekle (duplikasyon kontrolÃ¼)

ğŸ“Š Veri Depolama Stratejisi:
  1. Kitaplar tablosu (88) â†’ Ana referans tablosu, az UPDATE
  2. Ä°Ã§erik chunks â†’ AyrÄ± tablo (TOMEHUB_CONTENT), sÄ±k INSERT/UPDATE
  3. BaÄŸlantÄ± â†’ TITLE STRING MATCH (FOREIGN KEY deÄŸil)
  4. Kaynaklar â†’ SOURCE_TYPE enum tÃ¼rÃ¼ ile takip
  5. Multi-tenancy â†’ FIREBASE_UID ile izolasyon
""")

if __name__ == '__main__':
    DatabaseManager.init_pool()
    
    try:
        analyze_books_schema()
        analyze_books_data()
        analyze_books_relationships()
        analyze_content_by_book()
        analyze_book_metadata_quality()
        analyze_book_users()
        analyze_related_tables()
        generate_recommendations()
    finally:
        DatabaseManager.close_pool()
